{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code from fast.ai https://github.com/fastai/fastai/blob/master/courses/dl2/imdb.ipynb\n",
    "\n",
    "language models were trained using code and instructions from here https://github.com/fastai/fastai/tree/master/courses/dl2/imdb_scripts\n",
    "\n",
    "**Uses older fastai library version - https://forums.fast.ai/t/fastai-v0-7-install-issues-thread/24652 installation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _pickle as pickle, pandas as pd, numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "Read data and split it into test and train datasets.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_annotation = pd.read_csv('../uk_annotation.csv')\n",
    "ru_annotation = pd.read_csv('../ru_annotation.csv')\n",
    "\n",
    "htmls = pd.read_json('../htmls_sample.jl.bz2', lines=True, chunksize=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13it [01:41,  7.68s/it]\n"
     ]
    }
   ],
   "source": [
    "uk_ids = []; ru_ids = []\n",
    "for df in tqdm(htmls):\n",
    "    uk_ids.append(\n",
    "        df.loc[df.html_id.isin(uk_annotation.html_id)].copy(\n",
    "         ).reindex(['html_id', 'word_ids'], axis=1)\n",
    "    )\n",
    "    ru_ids.append(\n",
    "        df.loc[df.html_id.isin(ru_annotation.html_id)].copy(\n",
    "         ).reindex(['html_id', 'word_ids'], axis=1)\n",
    "    )\n",
    "    \n",
    "uk_ids = pd.concat(uk_ids, ignore_index=True\n",
    "                  ).merge(uk_annotation, on='html_id', how='left'\n",
    "                  ).sample(frac=1)\n",
    "ru_ids = pd.concat(ru_ids, ignore_index=True\n",
    "                  ).merge(ru_annotation, on='html_id', how='left'\n",
    "                  ).sample(frac=1)\n",
    "\n",
    "del uk_annotation, ru_annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ru_train_test_mask = np.random.choice([True, False], len(ru_ids), p=[0.2, 0.8])\n",
    "uk_train_test_mask = np.random.choice([True, False], len(uk_ids), p=[0.2, 0.8])\n",
    "\n",
    "# ids - lists of token ids in text\n",
    "ru_trn_ids = ru_ids.word_ids.values[~ru_train_test_mask]\n",
    "ru_val_ids = ru_ids.word_ids.values[ru_train_test_mask]\n",
    "uk_trn_ids = uk_ids.word_ids.values[~uk_train_test_mask]\n",
    "uk_val_ids = uk_ids.word_ids.values[uk_train_test_mask]\n",
    "\n",
    "#labels\n",
    "ru_trn_lab = ru_ids[['is_emo', 'is_arg', 'is_other']].values[~ru_train_test_mask]\n",
    "ru_val_lab = ru_ids[['is_emo', 'is_arg', 'is_other']].values[ru_train_test_mask]\n",
    "uk_trn_lab = uk_ids[['is_emo', 'is_arg', 'is_other']].values[~uk_train_test_mask]\n",
    "uk_val_lab = uk_ids[['is_emo', 'is_arg', 'is_other']].values[uk_train_test_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('itos_ru.pkl', 'rb') as f:\n",
    "    itos_ru = pickle.load(f)\n",
    "with open('itos_uk.pkl', 'rb') as f:\n",
    "    itos_uk = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relevant - irrelevant classifier\n",
    "Classify relevant news (Ukrainian politics, economy, important social issues) from irrelevant (sport, weather, celebrities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = lambda x : np.exp(x)/np.sum(np.exp(x)) # softmax activation\n",
    "sigm = lambda x: 1 / (1 + np.exp(-x))\n",
    "sigmv = np.vectorize(sigm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLAS_PATH = Path('ru/')\n",
    "# reads and saves models from this forlder / models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bptt,em_sz,nh,nl = 70,400,1150,3 # bptt - numper of tokens that model prosesses at once; em - embedding size\n",
    "# nh - n of cells in LSTM layers in pre-trained language model\n",
    "# nl - n of LSTM layers in language model\n",
    "vs = len(itos_ru) # len of token dictionary\n",
    "bs = 8 # batch size - reduce in case of memory error\n",
    "c = 2 # n of categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data in fastai format. Sortish sampler groups texts of same length in batch, so there will be less padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds = TextDataset(ru_trn_ids, ru_trn_lab[:, -1])\n",
    "val_ds = TextDataset(ru_val_ids, ru_val_lab[:, -1])\n",
    "trn_samp = SortishSampler(ru_trn_ids, key=lambda x: len(ru_trn_ids[x]), bs=bs//2)\n",
    "val_samp = SortSampler(ru_val_ids, key=lambda x: len(ru_val_ids[x]))\n",
    "trn_dl = DataLoader(trn_ds, bs//2, transpose=True, num_workers=1, pad_idx=1, sampler=trn_samp)\n",
    "val_dl = DataLoader(val_ds, bs, transpose=True, num_workers=1, pad_idx=1, sampler=val_samp)\n",
    "md = ModelData(CLAS_PATH, trn_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dps = np.array([0.4,0.5,0.05,0.3,0.4])*0.6 # dropouts for each level, increased comparing to default\n",
    "\n",
    "# model definition\n",
    "m = get_rnn_classifier(bptt, 15*70, c, vs, emb_sz=em_sz,\n",
    "                       n_hid=nh, n_layers=nl,\n",
    "                       pad_token=1, #token for padding\n",
    "                       #final layer. max and average pooling of LSTM states, and the last state\n",
    "                       layers=[em_sz*3, 50, c], \n",
    "                       # dropouts\n",
    "                       drops=[dps[4], 0.2],\n",
    "                       dropouti=dps[0],\n",
    "                       wdrop=dps[1],\n",
    "                       dropoute=dps[2],\n",
    "                       dropouth=dps[3])\n",
    "\n",
    "opt_fn = partial(optim.Adam, betas=(0.7, 0.99)) # Adam optimizer\n",
    "\n",
    "learn = RNN_Learner(md, TextModel(to_gpu(m)), opt_fn=opt_fn)\n",
    "learn.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)\n",
    "learn.clip=25. # maximum value of weights, left as default\n",
    "learn.metrics = [accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rates\n",
    "lr=3e-3\n",
    "lrs=np.array([1e-4,1e-4,1e-4,1e-3,1e-2])\n",
    "\n",
    "wd = 1e-7 # weight decay\n",
    "learn.load_encoder('fwd_ru_finetuned_lm_enc') # load pretrained language model encoder\n",
    "learn.freeze_to(-1) # freeze all layers (trained), except for the last feed-dorward one (randomly initialized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finds the best learning rate\n",
    "learn.lr_find(lrs/1000)\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training. 'use_wd_sched' tweaks weight regularisation, as described here\n",
    "# https://forums.fast.ai/t/new-adamw-optimizer-now-available/8518\n",
    "# clr decreases learning rate during training\n",
    "learn.fit(lrs, 1, wds=wd, cycle_len=1, use_clr=(8, 3), use_wd_sched=True)\n",
    "learn.sched.plot_loss()\n",
    "learn.save('ru_test_other_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('ru_test_other_0')\n",
    "learn.freeze_to(-2) # more unfreezing\n",
    "\n",
    "learn.fit(lrs, 1, wds=wd, cycle_len=1, use_clr=(8,3), use_wd_sched=True)\n",
    "learn.sched.plot_loss()\n",
    "learn.save('ru_test_other_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('ru_test_other_1')\n",
    "learn.unfreeze()\n",
    "\n",
    "learn.fit(lrs, 1, wds=wd, cycle_len=3, use_clr=(32,10), use_wd_sched=True)\n",
    "learn.sched.plot_loss()\n",
    "learn.save('ru_test_other_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_no_sample_dl = DataLoader(val_ds, bs, transpose=True, num_workers=1, pad_idx=1)\n",
    "preds = predict(learn.model, dl_pred)\n",
    "result = np.apply_along_axis(softmax, 1, preds)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thr = 0.68 # threshold after whisch to consider article irrelevant\n",
    "print(sklearn.metrics.classification_report(y_pred=result > thr,\n",
    "                                            y_true=ru_val_lab[:, -1],\n",
    "                                            labels=[1,0]))\n",
    "\n",
    "cm = sklearn.metrics.confusion_matrix(y_pred=result > thr,\n",
    "                                      y_true=ru_val_lab[:, -1],\n",
    "                                      labels=[1,0])\n",
    "\n",
    "cm / cm.sum(1)[:, None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### uk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "CLAS_PATH = Path('uk/')\n",
    "# reads and saves models from this forlder / models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bptt,em_sz,nh,nl = 70,400,1150,3 # bptt - numper of tokens that model prosesses at once; em - embedding size\n",
    "# nh - n of cells in LSTM layers in pre-trained language model\n",
    "# nl - n of LSTM layers in language model\n",
    "vs = len(itos_uk) # len of token dictionary\n",
    "bs = 32 # batch size - reduce in case of memory error\n",
    "c = 2 # n of categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trn_ds = TextDataset(uktrn_ids, uktrn_lab[:, -1])\n",
    "val_ds = TextDataset(ukval_ids, ukval_lab[:, -1])\n",
    "trn_samp = SortishSampler(uktrn_ids, key=lambda x: len(uktrn_ids[x]), bs=bs//2)\n",
    "val_samp = SortSampler(ukval_ids, key=lambda x: len(ukval_ids[x]))\n",
    "trn_dl = DataLoader(trn_ds, bs//2, transpose=True, num_workers=1, pad_idx=1, sampler=trn_samp)\n",
    "val_dl = DataLoader(val_ds, bs, transpose=True, num_workers=1, pad_idx=1, sampler=val_samp)\n",
    "md = ModelData(CLAS_PATH, trn_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dps = np.array([0.4,0.5,0.05,0.3,0.4])*0.6 # dropouts for each level, increased comparing to default\n",
    "\n",
    "# model definition\n",
    "m = get_rnn_classifier(bptt, 25*70, c, vs, emb_sz=em_sz,\n",
    "                       n_hid=nh, n_layers=nl,\n",
    "                       pad_token=1, #token for padding\n",
    "                       #final layer. max and average pooling of LSTM states, and the last state\n",
    "                       layers=[em_sz*3, 50, c], \n",
    "                       # dropouts\n",
    "                       drops=[dps[4], 0.2],\n",
    "                       dropouti=dps[0],\n",
    "                       wdrop=dps[1],\n",
    "                       dropoute=dps[2],\n",
    "                       dropouth=dps[3])\n",
    "\n",
    "opt_fn = partial(optim.Adam, betas=(0.7, 0.99)) # Adam optimizer\n",
    "\n",
    "learn = RNN_Learner(md, TextModel(to_gpu(m)), opt_fn=opt_fn)\n",
    "learn.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)\n",
    "learn.clip=25. # maximum value of weights, left as default\n",
    "learn.metrics = [accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# learning rates\n",
    "lr=3e-3\n",
    "lrs=np.array([1e-4,1e-4,1e-4,1e-3,1e-2])\n",
    "\n",
    "wd = 1e-7 # weight decay\n",
    "learn.load_encoder('fwd_uk_finetuned_lm_enc')\n",
    "learn.freeze_to(-1) # freeze all layers, except for the last feed-dorward one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# finds the best learning rate\n",
    "learn.lr_find(lrs/1000)\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# training. 'use_wd_sched' tweaks weight regularisation, as described here\n",
    "# https://forums.fast.ai/t/new-adamw-optimizer-now-available/8518\n",
    "# clr decreases learning rate during training\n",
    "learn.fit(lrs, 1, wds=wd, cycle_len=1, use_clr=(8, 3), use_wd_sched=True)\n",
    "learn.sched.plot_loss()\n",
    "learn.save('uk_test_other_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.load('uk_test_other_0')\n",
    "learn.freeze_to(-2) # more unfreezing\n",
    "\n",
    "learn.fit(lrs, 1, wds=wd, cycle_len=1, use_clr=(8,3), use_wd_sched=True)\n",
    "learn.sched.plot_loss()\n",
    "learn.save('uk_test_other_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.load('uk_test_other_1')\n",
    "learn.unfreeze()\n",
    "\n",
    "learn.fit(lrs, 1, wds=wd, cycle_len=3, use_clr=(32,10), use_wd_sched=True)\n",
    "learn.sched.plot_loss()\n",
    "learn.save('uk_test_other_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "val_no_sample_dl = DataLoader(val_ds, bs, transpose=True, num_workers=1, pad_idx=1)\n",
    "preds = predict(learn.model, dl_pred)\n",
    "result = np.apply_along_axis(softmax, 1, preds)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "thr = 0.55 # threshold after whisch to consider article irrelevant\n",
    "print(sklearn.metrics.classification_report(y_pred=result > thr,\n",
    "                                            y_true=uk_val_lab[:, -1],\n",
    "                                            labels=[1,0]))\n",
    "\n",
    "cm = sklearn.metrics.confusion_matrix(y_pred=result > thr,\n",
    "                                      y_true=uk_val_lab[:, -1],\n",
    "                                      labels=[1,0])\n",
    "\n",
    "cm / cm.sum(1)[:, None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulations classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multilabel output layer\n",
    "# from https://forums.fast.ai/t/multilabel-classification-with-ulmfit/19809/3\n",
    "class MultiLabelClassifier(nn.Module):\n",
    "    def __init__(self, y_range=None):\n",
    "        super().__init__()\n",
    "        self.y_range = y_range\n",
    "    \n",
    "    def forward(self, input):\n",
    "        x, raw_outputs, outputs = input\n",
    "        x = F.sigmoid(x)\n",
    "        # no y_range here\n",
    "        if (self.y_range):\n",
    "            x = x * (self.y_range[1] - self.y_range[0])\n",
    "            x = x + self.y_range[0]\n",
    "        return x, raw_outputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bptt,em_sz,nh,nl = 70,400,1150,3\n",
    "opt_fn = partial(optim.Adam, betas=(0.8, 0.99))\n",
    "bs = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### uk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLAS_PATH = Path('uk/')\n",
    "vs = len(itos_uk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({False: 1768, True: 1017})\n"
     ]
    }
   ],
   "source": [
    "# filter out irrelevant articles\n",
    "rel_uk_trn_ids0 = uk_trn_ids[uk_trn_lab[:, -1] == 0]\n",
    "rel_uk_trn_lab0 = uk_trn_lab[uk_trn_lab[:, -1] == 0, :-1]\n",
    "rel_uk_val_ids = uk_val_ids[uk_val_lab[:, -1] == 0]\n",
    "rel_uk_val_lab = uk_val_lab[uk_val_lab[:, -1] == 0, :-1]\n",
    "\n",
    "# Multiply manipulative texts to balance training set\n",
    "rel_uk_trn_ids = np.hstack([rel_uk_trn_ids0,\n",
    "                      rel_uk_trn_ids0[rel_uk_trn_lab0.any(1)],\n",
    "                      rel_uk_trn_ids0[rel_uk_trn_lab0.any(1)],])\n",
    "\n",
    "rel_uk_trn_lab = np.vstack([rel_uk_trn_lab0,\n",
    "                        rel_uk_trn_lab0[rel_uk_trn_lab0.any(1)],\n",
    "                        rel_uk_trn_lab0[rel_uk_trn_lab0.any(1)],])\n",
    "\n",
    "print(Counter(rel_uk_trn_lab.any(1)))\n",
    "# mix multiplied examples\n",
    "perm = np.random.permutation(len(rel_uk_trn_ids))\n",
    "rel_uk_trn_ids = rel_uk_trn_ids[perm]\n",
    "rel_uk_trn_lab = rel_uk_trn_lab[perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 2\n",
    "trn_ds = TextDataset(rel_uk_trn_ids, rel_uk_trn_lab.astype(np.float64))\n",
    "val_ds = TextDataset(rel_uk_val_ids, rel_uk_val_lab.astype(np.float64))\n",
    "trn_samp = SortishSampler(rel_uk_trn_ids, key=lambda x: len(rel_uk_trn_ids[x]), bs=bs//2)\n",
    "val_samp = SortSampler(rel_uk_val_ids, key=lambda x: len(rel_uk_val_ids[x]))\n",
    "trn_dl = DataLoader(trn_ds, bs//2, transpose=True, num_workers=1, pad_idx=1, sampler=trn_samp)\n",
    "val_dl = DataLoader(val_ds, bs, transpose=True, num_workers=1, pad_idx=1, sampler=val_samp)\n",
    "md = ModelData(CLAS_PATH, trn_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "dps = np.array([0.4,0.5,0.05,0.3,0.4])*0.65\n",
    "\n",
    "m = get_rnn_classifier(bptt, 15*70, c, vs, emb_sz=em_sz,\n",
    "                       n_hid=nh, n_layers=nl,\n",
    "                       pad_token=1,\n",
    "                       layers=[em_sz*3, 50, c],\n",
    "                       drops=[dps[4], 0.2],\n",
    "                       dropouti=dps[0],\n",
    "                       wdrop=dps[1],\n",
    "                       dropoute=dps[2],\n",
    "                       dropouth=dps[3])\n",
    "\n",
    "opt_fn = partial(optim.Adam, betas=(0.7, 0.99))\n",
    "\n",
    "learn = RNN_Learner(md, TextModel(to_gpu(m)), opt_fn=opt_fn)\n",
    "learn.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)\n",
    "learn.clip=25.\n",
    "    \n",
    "learn.model.add_module('2', MultiLabelClassifier())\n",
    "# different loss function - for multilabel with sigmoid activation\n",
    "learn.crit = F.binary_cross_entropy\n",
    "learn.metrics = [accuracy_thresh(0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs=np.array([1e-4,1e-4,1e-4,1e-3,1e-2])\n",
    "\n",
    "wd = 1e-7\n",
    "# wd = 0\n",
    "learn.load_encoder('fwd_uk_finetuned_lm_enc')\n",
    "learn.freeze_to(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05270a10ac7140f99a21f33849438c19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 454/697 [03:04<02:20,  1.73it/s, loss=1.47] "
     ]
    }
   ],
   "source": [
    "learn.lr_find(1/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lrs, 1, wds=wd, cycle_len=1, use_clr=(8, 3), use_wd_sched=True)\n",
    "learn.sched.plot_loss()\n",
    "learn.save('uk_test_mult_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('uk_test_mult_0')\n",
    "learn.freeze_to(-2)\n",
    "learn.fit(lrs, 1, wds=wd, cycle_len=1, use_clr=(8, 3), use_wd_sched=True)\n",
    "learn.sched.plot_loss()\n",
    "learn.save('uk_test_mult_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find(lr / 1000)\n",
    "learn.sched.plot()\n",
    "# change learning rate after checking lr search.\n",
    "# Ideal value is somewhat before the moment of steep increase in loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('uk_test_mult_1')\n",
    "learn.unfreeze()\n",
    "learn.fit(lrs/3, 1, wds=wd, cycle_len=1, use_clr=(32, 10), use_wd_sched=True)\n",
    "learn.sched.plot_loss()\n",
    "learn.save('uk_test_mult_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check on test set\n",
    "\n",
    "test set is labeled by 2 annotators, the quality is much better, than of general trainig annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialRNN(\n",
       "  (0): MultiBatchRNN(\n",
       "    (encoder): Embedding(40108, 400, padding_idx=1)\n",
       "    (encoder_with_dropout): EmbeddingDropout(\n",
       "      (embed): Embedding(40108, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDrop(\n",
       "        (module): LSTM(400, 1150)\n",
       "      )\n",
       "      (1): WeightDrop(\n",
       "        (module): LSTM(1150, 1150)\n",
       "      )\n",
       "      (2): WeightDrop(\n",
       "        (module): LSTM(1150, 400)\n",
       "      )\n",
       "    )\n",
       "    (dropouti): LockedDropout(\n",
       "    )\n",
       "    (dropouths): ModuleList(\n",
       "      (0): LockedDropout(\n",
       "      )\n",
       "      (1): LockedDropout(\n",
       "      )\n",
       "      (2): LockedDropout(\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): ModuleList(\n",
       "      (0): LinearBlock(\n",
       "        (lin): Linear(in_features=1200, out_features=50, bias=True)\n",
       "        (drop): Dropout(p=0)\n",
       "        (bn): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "      (1): LinearBlock(\n",
       "        (lin): Linear(in_features=50, out_features=2, bias=True)\n",
       "        (drop): Dropout(p=0)\n",
       "        (bn): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_pred = get_rnn_classifer(bptt, 25*70, 2, vs,\n",
    "                           emb_sz=em_sz, n_hid=nh, n_layers=nl, pad_token=1,\n",
    "                           drops=[0,0],\n",
    "                           layers=[em_sz*3, 50, c])\n",
    "\n",
    "load_model(m_pred, 'uk/models/uk_emo_arg_cls.h5')\n",
    "\n",
    "m_pred.cuda()\n",
    "m_pred.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uk_test = pd.read_json('uk_test_set.jl', lines=True)\n",
    "df_uk_test = df_uk_test.loc[(df_uk_test.other_check == 0)\n",
    "                            & df_uk_test.is_emo.notnull()\n",
    "                           ].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = TextDataset(df_uk_test.word_ids.values, df_uk_test[['emo_check', 'arg_check']].values.astype(int))\n",
    "dl = DataLoader(ds, batch_size=8, transpose=True, num_workers=3, pad_idx=1)\n",
    "pred = predict(m_pred, dl)\n",
    "result = sigmv(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.39      0.45        28\n",
      "          0       0.92      0.95      0.94       216\n",
      "\n",
      "avg / total       0.88      0.89      0.88       244\n",
      "\n",
      "emotionality \n",
      " [[0.39286 0.60714]\n",
      " [0.0463  0.9537 ]] \n",
      " [[ 11  17]\n",
      " [ 10 206]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.31      0.38        26\n",
      "          0       0.92      0.96      0.94       218\n",
      "\n",
      "avg / total       0.88      0.89      0.88       244\n",
      "\n",
      "argumentation \n",
      " [[0.30769 0.69231]\n",
      " [0.0367  0.9633 ]] \n",
      " [[  8  18]\n",
      " [  8 210]]\n"
     ]
    }
   ],
   "source": [
    "thr = 0.42 # threshold after which to consider article emotional\n",
    "print(sklearn.metrics.classification_report(y_pred=result[:, 0] > thr,\n",
    "                                            y_true=df_uk_test.emo_check,\n",
    "                                            labels=[1,0]))\n",
    "\n",
    "cm = sklearn.metrics.confusion_matrix(y_pred=result[:, 0] > thr,\n",
    "                                      y_true=df_uk_test.emo_check,\n",
    "                                      labels=[1,0])\n",
    "\n",
    "print('emotionality', '\\n', cm / cm.sum(1)[:, None], '\\n', cm)\n",
    "\n",
    "thr = 0.45 # threshold after which to consider article false argumentation\n",
    "print(sklearn.metrics.classification_report(y_pred=result[:, 1] > thr,\n",
    "                                            y_true=df_uk_test.arg_check,\n",
    "                                            labels=[1,0]))\n",
    "\n",
    "cm = sklearn.metrics.confusion_matrix(y_pred=result[:, 1] > thr,\n",
    "                                      y_true=df_uk_test.arg_check,\n",
    "                                      labels=[1,0])\n",
    "\n",
    "print('argumentation', '\\n', cm / cm.sum(1)[:, None], '\\n', cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLAS_PATH = Path('ru/')\n",
    "vs = len(itos_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({False: 6780, True: 6058})\n"
     ]
    }
   ],
   "source": [
    "# filter out irrelevant articles\n",
    "rel_ru_trn_ids0 = ru_trn_ids[ru_trn_lab[:, -1] == 0]\n",
    "rel_ru_trn_lab0 = ru_trn_lab[ru_trn_lab[:, -1] == 0, :-1]\n",
    "rel_ru_val_ids = ru_val_ids[ru_val_lab[:, -1] == 0]\n",
    "rel_ru_val_lab = ru_val_lab[ru_val_lab[:, -1] == 0, :-1]\n",
    "\n",
    "# Multiply manipulative texts to balance training set\n",
    "rel_ru_trn_ids = np.hstack([rel_ru_trn_ids0,\n",
    "                            rel_ru_trn_ids0[rel_ru_trn_lab0.any(1)],])\n",
    "\n",
    "rel_ru_trn_lab = np.vstack([rel_ru_trn_lab0,\n",
    "                            rel_ru_trn_lab0[rel_ru_trn_lab0.any(1)]\n",
    "                           ])\n",
    "\n",
    "print(Counter(rel_ru_trn_lab.any(1)))\n",
    "# mix multiplied examples\n",
    "perm = np.random.permutation(len(rel_ru_trn_ids))\n",
    "rel_ru_trn_ids = rel_ru_trn_ids[perm]\n",
    "rel_ru_trn_lab = rel_ru_trn_lab[perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 2\n",
    "trn_ds = TextDataset(rel_ru_trn_ids, rel_ru_trn_lab)\n",
    "val_ds = TextDataset(rel_ru_val_ids, rel_ru_val_lab)\n",
    "trn_samp = SortishSampler(rel_ru_trn_ids, key=lambda x: len(rel_ru_trn_ids[x]), bs=bs//2)\n",
    "val_samp = SortSampler(rel_ru_val_ids, key=lambda x: len(rel_ru_val_ids[x]))\n",
    "trn_dl = DataLoader(trn_ds, bs//2, transpose=True, num_workers=1, pad_idx=1, sampler=trn_samp)\n",
    "val_dl = DataLoader(val_ds, bs, transpose=True, num_workers=1, pad_idx=1, sampler=val_samp)\n",
    "md = ModelData(CLAS_PATH, trn_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "dps = np.array([0.4,0.5,0.05,0.3,0.4])*0.55\n",
    "\n",
    "m = get_rnn_classifier(bptt, 25*70, c, vs, emb_sz=em_sz,\n",
    "                       n_hid=nh, n_layers=nl,\n",
    "                       pad_token=1,\n",
    "                       layers=[em_sz*3, 50, c],\n",
    "                       drops=[dps[4], 0.2],\n",
    "                       dropouti=dps[0],\n",
    "                       wdrop=dps[1],\n",
    "                       dropoute=dps[2],\n",
    "                       dropouth=dps[3])\n",
    "\n",
    "opt_fn = partial(optim.Adam, betas=(0.7, 0.99))\n",
    "\n",
    "learn = RNN_Learner(md, TextModel(to_gpu(m)), opt_fn=opt_fn)\n",
    "learn.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)\n",
    "learn.clip=25.\n",
    "    \n",
    "learn.model.add_module('2', MultiLabelClassifier())\n",
    "# different loss function - for multilabel with sigmoid activation\n",
    "learn.crit = F.binary_cross_entropy\n",
    "learn.metrics = [accuracy_thresh(0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "??MultiBatchRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs=np.array([1e-4,1e-4,1e-4,1e-3,1e-2])\n",
    "\n",
    "wd = 1e-7\n",
    "# wd = 0\n",
    "learn.load_encoder('fwd_ru_finetuned_lm_enc')\n",
    "learn.freeze_to(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lrs, 1, wds=wd, cycle_len=1, use_clr=(8, 3), use_wd_sched=True)\n",
    "learn.sched.plot_loss()\n",
    "learn.save('ru_test_mult_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('ru_test_mult_0')\n",
    "learn.freeze_to(-2)\n",
    "learn.fit(lrs, 1, wds=wd, cycle_len=1, use_clr=(8, 3), use_wd_sched=True)\n",
    "learn.sched.plot_loss()\n",
    "learn.save('ru_test_mult_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('ru_test_mult_1')\n",
    "learn.unfreeze()\n",
    "learn.fit(lrs, 1, wds=wd, cycle_len=1, use_clr=(8, 3), use_wd_sched=True)\n",
    "learn.sched.plot_loss()\n",
    "learn.save('ru_test_mult_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialRNN(\n",
       "  (0): MultiBatchRNN(\n",
       "    (encoder): Embedding(60002, 400, padding_idx=1)\n",
       "    (encoder_with_dropout): EmbeddingDropout(\n",
       "      (embed): Embedding(60002, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDrop(\n",
       "        (module): LSTM(400, 1150)\n",
       "      )\n",
       "      (1): WeightDrop(\n",
       "        (module): LSTM(1150, 1150)\n",
       "      )\n",
       "      (2): WeightDrop(\n",
       "        (module): LSTM(1150, 400)\n",
       "      )\n",
       "    )\n",
       "    (dropouti): LockedDropout(\n",
       "    )\n",
       "    (dropouths): ModuleList(\n",
       "      (0): LockedDropout(\n",
       "      )\n",
       "      (1): LockedDropout(\n",
       "      )\n",
       "      (2): LockedDropout(\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): ModuleList(\n",
       "      (0): LinearBlock(\n",
       "        (lin): Linear(in_features=1200, out_features=50, bias=True)\n",
       "        (drop): Dropout(p=0)\n",
       "        (bn): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "      (1): LinearBlock(\n",
       "        (lin): Linear(in_features=50, out_features=2, bias=True)\n",
       "        (drop): Dropout(p=0)\n",
       "        (bn): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_pred = get_rnn_classifer(bptt, 25*70, 2, vs,\n",
    "                           emb_sz=em_sz, n_hid=nh, n_layers=nl, pad_token=1,\n",
    "                           drops=[0,0],\n",
    "                           layers=[em_sz*3, 50, c])\n",
    "\n",
    "# load_model(m_pred, 'ru/models/ru_test_mult_2')\n",
    "load_model(m_pred, 'ru/models/ru_arg_emo_cls.h5')\n",
    "\n",
    "m_pred.cuda()\n",
    "m_pred.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ru_test = pd.read_json('ru_test_set.jl', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = TextDataset(df_ru_test.word_ids.values, df_ru_test[['emo_check', 'arg_check']].values.astype(int))\n",
    "dl = DataLoader(ds, batch_size=8, transpose=True, num_workers=3, pad_idx=1)\n",
    "pred = predict(m_pred, dl)\n",
    "result = sigmv(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.61      0.65       111\n",
      "          0       0.89      0.92      0.91       388\n",
      "\n",
      "avg / total       0.85      0.85      0.85       499\n",
      "\n",
      "emotionality \n",
      " [[0.61261 0.38739]\n",
      " [0.0799  0.9201 ]] \n",
      " [[ 68  43]\n",
      " [ 31 357]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.55      0.64       136\n",
      "          0       0.85      0.94      0.89       363\n",
      "\n",
      "avg / total       0.83      0.83      0.82       499\n",
      "\n",
      "argumentation \n",
      " [[0.55147 0.44853]\n",
      " [0.06336 0.93664]] \n",
      " [[ 75  61]\n",
      " [ 23 340]]\n"
     ]
    }
   ],
   "source": [
    "thr = 0.36 # threshold after which to consider article irrelevant\n",
    "print(sklearn.metrics.classification_report(y_pred=result[:, 0] > thr,\n",
    "                                            y_true=df_ru_test.emo_check,\n",
    "                                            labels=[1,0]))\n",
    "\n",
    "cm = sklearn.metrics.confusion_matrix(y_pred=result[:, 0] > thr,\n",
    "                                      y_true=df_ru_test.emo_check,\n",
    "                                      labels=[1,0])\n",
    "\n",
    "print('emotionality', '\\n', cm / cm.sum(1)[:, None], '\\n', cm)\n",
    "\n",
    "thr = 0.55 # threshold after which to consider article irrelevant\n",
    "print(sklearn.metrics.classification_report(y_pred=result[:, 1] > thr,\n",
    "                                            y_true=df_ru_test.arg_check,\n",
    "                                            labels=[1,0]))\n",
    "\n",
    "cm = sklearn.metrics.confusion_matrix(y_pred=result[:, 1] > thr,\n",
    "                                      y_true=df_ru_test.arg_check,\n",
    "                                      labels=[1,0])\n",
    "\n",
    "print('argumentation', '\\n', cm / cm.sum(1)[:, None], '\\n', cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
